{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kursatkara/MAE_5020_Spring_2025/blob/master/06_01_simple_nn_hand_calculation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PyTorch Manual Neural Network Example with Specific Values\n",
        "import torch\n",
        "import math\n",
        "\n",
        "# Input values\n",
        "i1, i2 = 0.85, 0.25\n",
        "x = torch.tensor([[i1, i2]], dtype=torch.float32)\n",
        "\n",
        "# Target output\n",
        "y_true = torch.tensor([[1.0, 0.0]], dtype=torch.float32)\n",
        "\n",
        "# Initialize weights and biases with given values\n",
        "W1 = torch.tensor([[0.1, 0.2, 0.3],\n",
        "                   [0.4, 0.5, 0.6]], dtype=torch.float32, requires_grad=True)\n",
        "b1 = torch.tensor([[0.0, 0.0, 0.0]], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "W2 = torch.tensor([[0.25, 0.50],\n",
        "                   [0.1, 0.2],\n",
        "                   [0.3, 0.4]], dtype=torch.float32, requires_grad=True)\n",
        "b2 = torch.tensor([[0.0, 0.0]], dtype=torch.float32, requires_grad=True)\n",
        "\n",
        "# One forward pass with printing\n",
        "z1 = x @ W1 + b1\n",
        "a1 = torch.sigmoid(z1)\n",
        "print(\"Hidden layer input (z1):\", z1.detach().numpy())\n",
        "print(\"Hidden layer output (a1):\", a1.detach().numpy())\n",
        "\n",
        "z2 = a1 @ W2 + b2\n",
        "y_pred = torch.sigmoid(z2)\n",
        "print(\"Output layer input (z2):\", z2.detach().numpy())\n",
        "print(\"****** Predicted output (y_pred):\", y_pred.detach().numpy())\n",
        "\n",
        "# Compute loss (mean squared error)\n",
        "loss = torch.mean((y_true - y_pred) ** 2)\n",
        "print(\"Loss:\", loss.item())\n",
        "\n",
        "# Backpropagation\n",
        "loss.backward()\n",
        "\n",
        "# Print gradients for verification\n",
        "print(\"\\\\nGradients:\")\n",
        "print(\"dL/dW2:\", W2.grad)\n",
        "print(\"dL/db2:\", b2.grad)\n",
        "print(\"dL/dW1:\", W1.grad)\n",
        "print(\"dL/db1:\", b1.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRN4YfikOcoa",
        "outputId": "4b69939a-b329-4c28-d87e-9236c9155700"
      },
      "id": "MRN4YfikOcoa",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hidden layer input (z1): [[0.185      0.29500002 0.40500003]]\n",
            "Hidden layer output (a1): [[0.54611856 0.5732198  0.5998884 ]]\n",
            "Output layer input (z2): [[0.37381816 0.6276586 ]]\n",
            "****** Predicted output (y_pred): [[0.59238124 0.65195835]]\n",
            "Loss: 0.29560136795043945\n",
            "\\nGradients:\n",
            "dL/dW2: tensor([[-0.0538,  0.0808],\n",
            "        [-0.0564,  0.0848],\n",
            "        [-0.0590,  0.0887]])\n",
            "dL/db2: tensor([[-0.0984,  0.1479]])\n",
            "dL/dW1: tensor([[0.0104, 0.0041, 0.0060],\n",
            "        [0.0031, 0.0012, 0.0018]])\n",
            "dL/db1: tensor([[0.0122, 0.0048, 0.0071]])\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}